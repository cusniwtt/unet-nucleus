{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESMNOyeoPOTe"
      },
      "source": [
        "# Nuclie Semantic Segmentation - UNet using Tensorflow 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e61ef2d8-f315-4f7f-b07e-1de0f4e8441a",
        "_uuid": "1677fddbb95f7545b6540e9201f3339a0fdbfc5d",
        "id": "kyyE6xeHPOTl"
      },
      "source": [
        "# Intro\n",
        "- Dataset used is from Kaggle's Data Science Bowl 2018 - Nuclei Segmentation\n",
        "- The architecture used is [U-Net](https://arxiv.org/abs/1505.04597), which is very common for image segmentation problems such as this.\n",
        "- This notebook is inspired from the great kernel [Keras U-net starter - LB 0.277](https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277) by Kjetil Åmdal-Sævik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FtGpSvl2eq2",
        "outputId": "01b9eb99-5767-4b61-997d-a3c2475c897d"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFTLqTBlaXca",
        "outputId": "840bd4a4-8310-4fb5-a53b-e2b556ca3e59"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2",
        "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f",
        "id": "GhEVrsrdPOTl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, add, multiply\n",
        "from keras.layers import Dropout, Lambda\n",
        "from keras.layers import Conv2D, Conv2DTranspose, BatchNormalization\n",
        "from keras.layers import MaxPooling2D, UpSampling2D\n",
        "from keras.layers import concatenate, Activation\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLV0HVwgZF0v"
      },
      "source": [
        "### Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuAJQi_CZF0v"
      },
      "outputs": [],
      "source": [
        "def prediction(model_path, X_test, img_size = (256, 256), thres = 0.5, verbose = 1):\n",
        "    # Predict on train, val and test\n",
        "    model = load_model(model_path)\n",
        "    preds_test = model.predict(X_test, verbose=verbose)\n",
        "\n",
        "    # Threshold predictions\n",
        "    preds_test_t = (preds_test > thres).astype(np.uint8)\n",
        "\n",
        "    # Create list of upsampled test masks\n",
        "    preds_test_upsampled = []\n",
        "    for i in range(len(preds_test_t)):\n",
        "        preserve = np.squeeze(preds_test_t[i])\n",
        "        res = resize(preserve, img_size, mode='constant', preserve_range=True)\n",
        "        preds_test_upsampled.append(res.astype(np.uint8))\n",
        "    return preds_test_upsampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWTeGqDRZF0v"
      },
      "source": [
        "### Watershed for split nucleus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rxjSI6AZF0v"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import scipy.ndimage as ndi\n",
        "from skimage.segmentation import watershed, find_boundaries\n",
        "from skimage.feature import corner_peaks\n",
        "from skimage.morphology import binary_dilation, disk\n",
        "from skimage.color import label2rgb\n",
        "from skimage.measure import regionprops_table\n",
        "\n",
        "def make_boundary_image(L, A, thickness=1, color=(255,255,85), rescale_hist=True):\n",
        "    if A.ndim == 2:\n",
        "        A = np.stack((A,A,A), axis=2)\n",
        "    if rescale_hist:\n",
        "        A = np.interp(A, (np.amin(A), np.amax(A)), (0,255)).astype(np.uint8)\n",
        "    else:\n",
        "        A = A.astype(np.uint8)\n",
        "\n",
        "    mask = find_boundaries(L)\n",
        "    mask = binary_dilation(mask, footprint=disk(thickness))\n",
        "\n",
        "    R = A[:,:,0].copy()\n",
        "    G = A[:,:,1].copy()\n",
        "    B = A[:,:,2].copy()\n",
        "\n",
        "    R[mask] = color[0]\n",
        "    G[mask] = color[1]\n",
        "    B[mask] = color[2]\n",
        "\n",
        "    return np.stack((R,G,B), axis=2)\n",
        "\n",
        "def labelvis(A, L, bg_color='b'):\n",
        "    bg_color_code = {\n",
        "        'b': (0.1,0.1,0.5),\n",
        "        'g': (0.1,0.5,0.1),\n",
        "    }  \n",
        "    A = label2rgb(L, A, bg_label=0, bg_color=bg_color_code[bg_color], alpha=0.3, image_alpha=1)\n",
        "    A = np.interp(A, (0,1), (0,255)).astype(np.uint8)\n",
        "    A = make_boundary_image(L, A)\n",
        "    return A\n",
        "\n",
        "# Create predict boundary image with label\n",
        "# Input: image, label\n",
        "# Output: rgb_watershed, boundary, mask, dataframe\n",
        "def create_boundary(img, label):\n",
        "    #Threshold image to binary using OTSU. ALl thresholded pixels will be set to 255\n",
        "    ret1, thresh = cv2.threshold(label, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    \n",
        "    # Borrow from imageMKS\n",
        "    # Step 9: distance transform\n",
        "    distance = ndi.distance_transform_edt(thresh)\n",
        "    \n",
        "    # Step 10: mark the maxima in the distance transform and assign labels\n",
        "    peak_markers = corner_peaks(distance, min_distance=5, indices=False)\n",
        "    peak_markers = ndi.label(peak_markers)[0]\n",
        "    \n",
        "    # Step 11: separate touching nuclei using the watershed markers\n",
        "    markers = watershed(label, peak_markers, mask=label)\n",
        "    \n",
        "    # Step 13: reassigning labels, so that they are continuously numbered\n",
        "    old_labels = np.unique(markers)\n",
        "    for i in range(len(old_labels)):\n",
        "        markers[markers == old_labels[i]] = i\n",
        "    \n",
        "    #Let us color boundaries in yellow. \n",
        "    img[markers == -1] = [0,255,255]  \n",
        "    \n",
        "    img_rgb = label2rgb(markers, bg_label=0)\n",
        "    boundary = labelvis(img, markers)\n",
        "    \n",
        "    # regionprops function in skimage measure module calculates useful parameters for each object.\n",
        "    params = ['label', 'area', 'bbox', 'equivalent_diameter', 'mean_intensity', 'solidity']\n",
        "    props = regionprops_table(markers, intensity_image=X_test[0], properties=params)\n",
        "    df = pd.DataFrame(props)\n",
        "    \n",
        "    return img_rgb, boundary, markers, df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YdGAF_woPOTm",
        "outputId": "7996d864-8abd-45f8-9a98-84c8e1f5aabd"
      },
      "outputs": [],
      "source": [
        "# Set some parameters\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 3\n",
        "TRAIN_PATH = 'dataset/stage1_train/'\n",
        "TEST_PATH = 'dataset/stage1_test/'\n",
        "\n",
        "dir_path = ''\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
        "seed = 42\n",
        "random.seed = seed\n",
        "np.random.seed = seed\n",
        "\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ffa0caf0-2d1b-40f2-865b-8e6db88526b6",
        "_uuid": "3fb9d6530fbbd0e22e41fc4fd9fd9fc0bff027ac",
        "id": "QeJvhGJRPOTo"
      },
      "outputs": [],
      "source": [
        "# Get train and test IDs\n",
        "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
        "test_ids = next(os.walk(TEST_PATH))[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "59c4a25d-645f-4b74-9c53-145ac78cc481",
        "_uuid": "875af74f980236825de3a650825b46e25632422c",
        "id": "MWz-i4iXPOTo"
      },
      "source": [
        "# Get the data\n",
        "- Downsample both the training and test images to reduce computations\n",
        "- Retain record of the original sizes of the test images to upsample predicted masks and create correct run-length encodings "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca0cc34b-c26f-41ee-88d7-975aebdb634e",
        "_uuid": "9e389ba8bdb5b6fc03b231b6a6c84a8bde634053",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVXaT7BJPOTo",
        "outputId": "87ffaba3-96dd-40ad-e086-ef5887e59843",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get and resize train images and masks\n",
        "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "print('Getting and resizing train images and masks ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    \n",
        "    #Read image files iteratively\n",
        "    path = TRAIN_PATH + id_\n",
        "    img = imread(dir_path + path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    \n",
        "    #Append image to numpy array for train dataset\n",
        "    X_train[n] = img\n",
        "    \n",
        "    #Read corresponding mask files iteratively\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "    \n",
        "    #Looping through masks\n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "\n",
        "        # Remove .DS_Store file\n",
        "        if mask_file == '.DS_Store':\n",
        "            continue\n",
        "        \n",
        "        #Read individual masks\n",
        "        mask_ = imread(dir_path + path + '/masks/' + mask_file)\n",
        "        \n",
        "        #Expand individual mask dimensions\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n",
        "\n",
        "        #Overlay individual masks to create a final mask for corresponding image\n",
        "        try:\n",
        "            mask = np.maximum(mask, mask_)\n",
        "        except:\n",
        "            print(mask_file)\n",
        "    \n",
        "    #Append mask to numpy array for train dataset\n",
        "    Y_train[n] = mask\n",
        "\n",
        "\n",
        "# Get and resize test images\n",
        "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_test = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "sizes_test = []\n",
        "print('Getting and resizing test images ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "    path = TEST_PATH + id_\n",
        "    \n",
        "    #Read images iteratively\n",
        "    img = imread(dir_path + path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    \n",
        "    #Get test size\n",
        "    sizes_test.append([img.shape[0], img.shape[1]])\n",
        "    \n",
        "    #Resize image to match training data\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    \n",
        "    #Append image to numpy array for test dataset\n",
        "    X_test[n] = img\n",
        "\n",
        "    #Read corresponding mask files iteratively\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "    \n",
        "    #Looping through masks\n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "\n",
        "        # Remove .DS_Store file\n",
        "        if mask_file == '.DS_Store':\n",
        "            continue\n",
        "        \n",
        "        #Read individual masks\n",
        "        mask_ = imread(dir_path + path + '/masks/' + mask_file)\n",
        "        \n",
        "        #Expand individual mask dimensions\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n",
        "\n",
        "        #Overlay individual masks to create a final mask for corresponding image\n",
        "        try:\n",
        "            mask = np.maximum(mask, mask_)\n",
        "        except:\n",
        "            print(mask_file)\n",
        "    \n",
        "    #Append mask to numpy array for train dataset\n",
        "    Y_test[n] = mask\n",
        "\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c0523b03-1fc5-4505-a1b8-eb35ee617c8a",
        "_uuid": "d4f8327802a1ec6139ce0585953986272ba62ce1",
        "id": "z3eBRkYZPOTp"
      },
      "source": [
        "## Visualize imported data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "88829b53-50ce-45d9-9540-77dd7384ad4c",
        "_uuid": "283af26f0860b7069bdfd133c746e5d20971542c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "LTHVzBiqPOTp",
        "outputId": "3abb7271-f51d-442f-e530-defa449bce9e"
      },
      "outputs": [],
      "source": [
        "# Check if training data looks all right\n",
        "ix = random.randint(0, len(train_ids))\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhfN4WTnZF0y",
        "outputId": "359fc3b6-503c-4275-aa5e-d87aeda04792"
      },
      "outputs": [],
      "source": [
        "# Validation split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axUYmjq1POTq"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcxxv4EnPOTq",
        "outputId": "4cb5e6c4-5907-4af1-98ee-d72e4f1cfae5"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.Resize(width=256, height=256),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.Rotate(limit=45, p=0.5),\n",
        "    A.CLAHE(p=0.5),\n",
        "])\n",
        "rounds = 10\n",
        "X_train_aug = np.zeros((0, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train_aug = np.zeros((0, IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "print('Augmentation train images and masks ... ')\n",
        "for r in range(rounds):\n",
        "    for n, id_ in tqdm(enumerate(X_train), total=X_train.shape[0]):\n",
        "        X_img = X_train[n]\n",
        "        Y_img = Y_train[n]*1\n",
        "        augmented = transform(image=X_img, mask=Y_img.astype(np.uint8))\n",
        "        if not np.any(augmented['mask']):\n",
        "            continue\n",
        "        else:\n",
        "            X_train_aug = np.append(X_train_aug, augmented['image'].reshape(1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), axis=0)\n",
        "            Y_train_aug = np.append(Y_train_aug, augmented['mask'].astype(bool).reshape(1, IMG_HEIGHT, IMG_WIDTH, 1), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO0hWVE6POTq",
        "outputId": "460ce821-f782-4577-cda7-fbcd59fe0313"
      },
      "outputs": [],
      "source": [
        "print(X_train_aug.shape)\n",
        "print(Y_train_aug.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "s6qw56JPPOTr",
        "outputId": "c4d19acb-38f2-4b2e-daed-f3998cbd42c6"
      },
      "outputs": [],
      "source": [
        "# Check if training data looks all right\n",
        "X_train = X_train_aug\n",
        "Y_train = Y_train_aug\n",
        "\n",
        "ix = random.sample(range(0, X_train.shape[0]), 16)\n",
        "fig, axs = plt.subplots(4, 8, figsize=(15, 8))\n",
        "row = 0\n",
        "col = 0\n",
        "for i in ix:\n",
        "  axs[row][col].imshow(X_train[i])\n",
        "  axs[row+1][col].imshow(np.squeeze(Y_train[i]))\n",
        "  col = col + 1\n",
        "  if col == 8:\n",
        "    col = 0\n",
        "    row = row + 2\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c3b9f148-1dba-4b6a-981b-6cdbf394fc3c",
        "_uuid": "986488a4c5223576be370e224426a30431911eb2",
        "id": "GkZA6dd9POTr"
      },
      "source": [
        "# Build and train our neural network\n",
        "Next we build our U-Net model, loosely based on [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf) and very similar to [this repo](https://github.com/jocicmarko/ultrasound-nerve-segmentation) from the Kaggle Ultrasound Nerve Segmentation competition.\n",
        "\n",
        "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" alt=\"UNet\" style=\"height: 400px; width:600px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OymkzMDRPOTr"
      },
      "source": [
        "## U-Net\n",
        "from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c1dbc57c-b497-4ccb-b077-2053203ab7ed",
        "_uuid": "0aa97d66c29f45dfac9b0f45fcf74ba0e778ba5d",
        "id": "G9NqwcmpPOTs"
      },
      "outputs": [],
      "source": [
        "# Build U-Net model\n",
        "\n",
        "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.2):\n",
        "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = BatchNormalization()(c)\n",
        "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    c = BatchNormalization()(c)\n",
        "    p = MaxPooling2D((2, 2), (2, 2))(c)\n",
        "    p = Dropout(dropout)(p)\n",
        "    return c, p\n",
        "\n",
        "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.3):\n",
        "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = BatchNormalization()(c)\n",
        "    c = Dropout(dropout)(c)\n",
        "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    c = BatchNormalization()(c)\n",
        "    return c\n",
        "\n",
        "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.2):\n",
        "    us = UpSampling2D((2, 2))(x)\n",
        "    concat = concatenate([us, skip])\n",
        "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
        "    c = BatchNormalization()(c)\n",
        "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    c = BatchNormalization()(c)\n",
        "    c = Dropout(dropout)(c)\n",
        "    return c\n",
        "\n",
        "def unet_model(filters=64, input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), nn_name=\"unet\"):\n",
        "    inputs = Input(input)\n",
        "    s = Lambda(lambda x: x / 255)(inputs)\n",
        "    down1 = down_block(s, filters, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.1)\n",
        "    down2 = down_block(down1[1], filters*2, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.1)\n",
        "    down3 = down_block(down2[1], filters*4, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.2)\n",
        "    down4 = down_block(down3[1], filters*8, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.2)\n",
        "    bottleneck1 = bottleneck(down4[1], filters*16, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.3)\n",
        "    up1 = up_block(bottleneck1, down4[0], filters*8, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.2)\n",
        "    up2 = up_block(up1, down3[0], filters*4, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.2)\n",
        "    up3 = up_block(up2, down2[0], filters*2, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.1)\n",
        "    up4 = up_block(up3, down1[0], filters, kernel_size=(3, 3), padding=\"same\", strides=1, dropout=0.1)\n",
        "    outputs = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(up4)\n",
        "    model = Model(inputs=[inputs], outputs=[outputs], name=nn_name)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU2TB2B-ZF00",
        "outputId": "3733b96c-02cd-4b5c-cf2d-e9b0336ff1bc"
      },
      "outputs": [],
      "source": [
        "model_repr = unet_model(filters=64, input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "model_repr.summary()\n",
        "del(model_repr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydi5AeZJPOTs"
      },
      "source": [
        "### Optimizer Loss Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpcA-nThPOTs"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "from keras import optimizers\n",
        "sgd = optimizers.SGD(learning_rate=0.002, decay=0.00003, momentum=0.9)\n",
        "adam = optimizers.Adam(learning_rate=0.002, decay=0.00003)\n",
        "\n",
        "# Loss function\n",
        "from keras.losses import BinaryCrossentropy\n",
        "bce = BinaryCrossentropy()\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def jacard_coef_loss(y_true, y_pred):\n",
        "    return -jacard_coef(y_true, y_pred)\n",
        "\n",
        "# Metrics\n",
        "from keras.metrics import Recall, Precision\n",
        "recall = Recall()\n",
        "precision = Precision()\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "# Fit model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=4, min_lr=0.00001, verbose=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ifBJ8x6LPOTt"
      },
      "source": [
        "### Adam, BCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "rl_1B_qSPOTt",
        "outputId": "6af0242d-87fa-439d-fd30-a40bf8d4917b"
      },
      "outputs": [],
      "source": [
        "# Adam, BCE, batch_size=8\n",
        "logs_p = 'logs/unet_64_adam_bce_8.csv'\n",
        "weights_p = 'weights/unet_64_adam_bce_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = adam\n",
        "loss_f = [bce]\n",
        "metrics_f = [recall, precision,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "  model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SGD, BCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anOiZsocPOTt"
      },
      "outputs": [],
      "source": [
        "# SGD, BCE, batch_size=8\n",
        "logs_p = 'logs/unet_64_sgd_bce_8.csv'\n",
        "weights_p = 'weights/unet_64_sgd_bce_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = sgd\n",
        "loss_f = [bce]\n",
        "metrics_f = [recall, precision,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "  model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YwLdhAT94nL1"
      },
      "source": [
        "### Adam, DICE + Jaccard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQFic6s99RyI",
        "outputId": "fba50e4e-8552-4913-c8dc-6237eb00ea20"
      },
      "outputs": [],
      "source": [
        "# Adam, Dice+Jacard, batch_size=8\n",
        "logs_p = 'logs/unet_64_adam_dice+jacard_8.csv'\n",
        "weights_p = 'weights/unet_64_adam_dice+jacard_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = adam\n",
        "loss_f = [dice_coef_loss, jacard_coef_loss]\n",
        "metrics_f = [dice_coef, jacard_coef,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "  model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SGD, DICE + Jaccard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYRFYAKAZF01",
        "outputId": "bdd25ca7-5bd1-4134-f6a4-c78a7352ad7b"
      },
      "outputs": [],
      "source": [
        "# SGD, Dice+Jacard, batch_size=8\n",
        "logs_p = 'logs/unet_64_sgd_dice+jacard_8.csv'\n",
        "weights_p = 'weights/unet_64_sgd_dice+jacard_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = sgd\n",
        "loss_f = [dice_coef_loss, jacard_coef_loss]\n",
        "metrics_f = [dice_coef, jacard_coef,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "  model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cv4tn9INi87D"
      },
      "source": [
        "## U-Net with InceptionResNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhCwYryfi87D"
      },
      "outputs": [],
      "source": [
        "# Create U-Net model\n",
        "from keras.applications import InceptionResNetV2\n",
        "from keras.layers import ZeroPadding2D\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = concatenate([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_inception_resnetv2_unet(input_shape):\n",
        "    \"\"\" Input \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\" Pre-trained InceptionResNetV2 Model \"\"\"\n",
        "    encoder = InceptionResNetV2(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1 = encoder.get_layer(\"input_1\").output           ## (512 x 512)\n",
        "\n",
        "    s2 = encoder.get_layer(\"activation\").output        ## (255 x 255)\n",
        "    s2 = ZeroPadding2D(( (1, 0), (1, 0) ))(s2)         ## (256 x 256)\n",
        "\n",
        "    s3 = encoder.get_layer(\"activation_3\").output      ## (126 x 126)\n",
        "    s3 = ZeroPadding2D((1, 1))(s3)                     ## (128 x 128)\n",
        "\n",
        "    s4 = encoder.get_layer(\"activation_74\").output      ## (61 x 61)\n",
        "    s4 = ZeroPadding2D(( (2, 1),(2, 1) ))(s4)           ## (64 x 64)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = encoder.get_layer(\"activation_161\").output     ## (30 x 30)\n",
        "    b1 = ZeroPadding2D((1, 1))(b1)                      ## (32 x 32)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
        "    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
        "    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
        "    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
        "\n",
        "    \"\"\" Output \"\"\"\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"InceptionResNetV2_U-Net\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = build_inception_resnetv2_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5vHBq7ui87D"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "from keras import optimizers\n",
        "sgd = optimizers.SGD(learning_rate=0.002, decay=0.00003, momentum=0.9)\n",
        "adam = optimizers.Adam(learning_rate=0.002, decay=0.00003)\n",
        "\n",
        "# Loss function\n",
        "from keras.losses import BinaryCrossentropy\n",
        "bce = BinaryCrossentropy()\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def jacard_coef_loss(y_true, y_pred):\n",
        "    return -jacard_coef(y_true, y_pred)\n",
        "\n",
        "# Metrics\n",
        "from keras.metrics import Recall, Precision\n",
        "recall = Recall()\n",
        "precision = Precision()\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "# Fit model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=4, min_lr=0.00001, verbose=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adam, BCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NamQC-qdi87D",
        "outputId": "5171c49d-30d1-45ae-cd74-f16599f7c307"
      },
      "outputs": [],
      "source": [
        "# Adam, BCE, batch_size=8\n",
        "logs_p = 'logs/irnv2_unet_64_adam_bce_8.csv'\n",
        "weights_p = 'weights/irnv2_unet_64_adam_bce_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = adam\n",
        "loss_f = [bce]\n",
        "metrics_f = [recall, precision,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "    model = build_inception_resnetv2_unet(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SGD, BCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SGD, BCE, batch_size=8\n",
        "logs_p = 'logs/irnv2_unet_64_sgd_bce_8.csv'\n",
        "weights_p = 'weights/irnv2_unet_64_sgd_bce_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = sgd\n",
        "loss_f = [bce]\n",
        "metrics_f = [recall, precision,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "    model = build_inception_resnetv2_unet(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adam, DICE + Jaccard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adam, Dice+Jacard, batch_size=8\n",
        "logs_p = 'logs/irnv2_unet_64_adam_dice+jacard_8.csv'\n",
        "weights_p = 'weights/irnv2_unet_64_adam_dice+jacard_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = adam\n",
        "loss_f = [dice_coef_loss, jacard_coef_loss]\n",
        "metrics_f = [dice_coef, jacard_coef,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "    model = build_inception_resnetv2_unet(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SGD, DICE + Jaccard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adam, Dice+Jacard, batch_size=8\n",
        "logs_p = 'logs/irnv2_unet_64_adam_dice+jacard_8.csv'\n",
        "weights_p = 'weights/irnv2_unet_64_adam_dice+jacard_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = sgd\n",
        "loss_f = [dice_coef_loss, jacard_coef_loss]\n",
        "metrics_f = [dice_coef, jacard_coef,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "    model = build_inception_resnetv2_unet(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AI-E1kNMwMuW"
      },
      "source": [
        "## Residual Attention U-Net with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-Samzp6u_Vq"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "\n",
        "    conv = Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n",
        "    if batch_norm is True:\n",
        "        conv = BatchNormalization(axis=3)(conv)\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = BatchNormalization(axis=3)(conv)\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "    \n",
        "    if dropout > 0:\n",
        "        conv = Dropout(dropout)(conv)\n",
        "\n",
        "    return conv\n",
        "\n",
        "\n",
        "def repeat_elem(tensor, rep):\n",
        "    # lambda function to repeat Repeats the elements of a tensor along an axis\n",
        "    #by a factor of rep.\n",
        "    # If tensor has shape (None, 256,256,3), lambda will return a tensor of shape \n",
        "    #(None, 256,256,6), if specified axis=3 and rep=2.\n",
        "\n",
        "     return Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
        "                          arguments={'repnum': rep})(tensor)\n",
        "\n",
        "\n",
        "def res_conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "    '''\n",
        "    Residual convolutional layer.\n",
        "    Two variants....\n",
        "    Either put activation function before the addition with shortcut\n",
        "    or after the addition (which would be as proposed in the original resNet).\n",
        "    \n",
        "    1. conv - BN - Activation - conv - BN - Activation \n",
        "                                          - shortcut  - BN - shortcut+BN\n",
        "                                          \n",
        "    2. conv - BN - Activation - conv - BN   \n",
        "                                     - shortcut  - BN - shortcut+BN - Activation                                     \n",
        "    \n",
        "    Check fig 4 in https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf\n",
        "    '''\n",
        "\n",
        "    conv = Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        conv = BatchNormalization(axis=3)(conv)\n",
        "    conv = Activation('relu')(conv)\n",
        "    \n",
        "    conv = Conv2D(size, (filter_size, filter_size), padding='same')(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = BatchNormalization(axis=3)(conv)\n",
        "    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut\n",
        "    if dropout > 0:\n",
        "        conv = Dropout(dropout)(conv)\n",
        "\n",
        "    shortcut = Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        shortcut = BatchNormalization(axis=3)(shortcut)\n",
        "\n",
        "    res_path = add([shortcut, conv])\n",
        "    res_path = Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)\n",
        "    return res_path\n",
        "\n",
        "def gating_signal(input, out_size, batch_norm=False):\n",
        "    \"\"\"\n",
        "    resize the down layer feature map into the same dimension as the up layer feature map\n",
        "    using 1x1 conv\n",
        "    :return: the gating feature map with the same dimension of the up layer feature map\n",
        "    \"\"\"\n",
        "    x = Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batch_norm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "\n",
        "# Getting the x signal to the same shape as the gating signal\n",
        "    theta_x = Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "# Getting the gating signal to the same number of filters as the inter_shape\n",
        "    phi_g = Conv2D(inter_shape, (1, 1), padding='same')(gating)\n",
        "    upsample_g = Conv2DTranspose(inter_shape, (3, 3),\n",
        "                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
        "                                 padding='same')(phi_g)  # 16\n",
        "\n",
        "    concat_xg = add([upsample_g, theta_x])\n",
        "    act_xg = Activation('relu')(concat_xg)\n",
        "    psi = Conv2D(1, (1, 1), padding='same')(act_xg)\n",
        "    sigmoid_xg = Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n",
        "\n",
        "    y = multiply([upsample_psi, x])\n",
        "\n",
        "    result = Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
        "    result_bn = BatchNormalization()(result)\n",
        "    return result_bn\n",
        "\n",
        "def Attention_ResUNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n",
        "    '''\n",
        "    Rsidual UNet, with attention \n",
        "    \n",
        "    '''\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of basic filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "    # input data\n",
        "    # dimension of the image depth\n",
        "    inputs = Input(input_shape, dtype=tf.float32)\n",
        "    axis = 3\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, double residual convolution + pooling\n",
        "    conv_128 = res_conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "    # DownRes 2\n",
        "    conv_64 = res_conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = res_conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = res_conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = res_conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
        "    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)\n",
        "    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n",
        "    up_16 = UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = concatenate([up_16, att_16], axis=axis)\n",
        "    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
        "    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
        "    up_32 = UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = concatenate([up_32, att_32], axis=axis)\n",
        "    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
        "    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
        "    up_64 = UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = concatenate([up_64, att_64], axis=axis)\n",
        "    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
        "    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
        "    up_128 = UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = concatenate([up_128, att_128], axis=axis)\n",
        "    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "    \n",
        "    conv_final = Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = BatchNormalization(axis=axis)(conv_final)\n",
        "    conv_final = Activation('sigmoid')(conv_final)  #Change to softmax for multichannel\n",
        "\n",
        "    # Model integration\n",
        "    model = Model(inputs, conv_final, name=\"AttentionResUNet\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1iLgCjaxH7t",
        "outputId": "5db65512-a6e3-47d9-daac-4563c53d87d2"
      },
      "outputs": [],
      "source": [
        "input_shape = (IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS)\n",
        "model = Attention_ResUNet(input_shape, NUM_CLASSES=1, dropout_rate=0.1, batch_norm=True)\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "from keras import optimizers\n",
        "sgd = optimizers.SGD(learning_rate=0.002, decay=0.00003, momentum=0.9)\n",
        "adam = optimizers.Adam(learning_rate=0.002, decay=0.00003)\n",
        "\n",
        "# Loss function\n",
        "from keras.losses import BinaryCrossentropy\n",
        "bce = BinaryCrossentropy()\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def jacard_coef_loss(y_true, y_pred):\n",
        "    return -jacard_coef(y_true, y_pred)\n",
        "\n",
        "# Metrics\n",
        "from keras.metrics import Recall, Precision\n",
        "recall = Recall()\n",
        "precision = Precision()\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "# Fit model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=4, min_lr=0.00001, verbose=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adam, BCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asqkzmULygdN",
        "outputId": "1c9748fb-d31a-44d6-d535-8a329ec67c01"
      },
      "outputs": [],
      "source": [
        "# Adam, BCE, batch_size=8\n",
        "logs_p = 'logs/ra_unet_64_adam_bce_8.csv'\n",
        "weights_p = 'weights/ra_unet_64_adam_bce_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = adam\n",
        "loss_f = [bce]\n",
        "metrics_f = [recall, precision,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "    model = build_inception_resnetv2_unet(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SGD, BCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adam, BCE, batch_size=8\n",
        "logs_p = 'logs/ra_unet_64_adam_bce_8.csv'\n",
        "weights_p = 'weights/ra_unet_64_adam_bce_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = sgd\n",
        "loss_f = [bce]\n",
        "metrics_f = [recall, precision,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "    model = build_inception_resnetv2_unet(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adam, DICE + Jaccard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adam, Dice+Jacard, batch_size=8\n",
        "logs_p = 'logs/ra_unet_64_adam_dice+jacard_8.csv'\n",
        "weights_p = 'weights/ra_unet_64_adam_dice+jacard_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = adam\n",
        "loss_f = [dice_coef_loss, jacard_coef_loss]\n",
        "metrics_f = [dice_coef, jacard_coef,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "    model = build_inception_resnetv2_unet(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SGD, DICE + Jaccard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adam, Dice+Jacard, batch_size=8\n",
        "logs_p = 'logs/ra_unet_64_adam_dice+jacard_8.csv'\n",
        "weights_p = 'weights/ra_unet_64_adam_dice+jacard_8.h5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(weights_p, verbose=1, save_best_only=True)\n",
        "callbacks_f = [earlystopper, checkpointer, reduce_lr, CSVLogger(logs_p, append=True, separator=';')]\n",
        "optimizer_f = sgd\n",
        "loss_f = [dice_coef_loss, jacard_coef_loss]\n",
        "metrics_f = [dice_coef, jacard_coef,]\n",
        "batch_s = 8 * tpu_strategy.num_replicas_in_sync # with TPU\n",
        "#batch_s = 8\n",
        "epochs_s = 100\n",
        "\n",
        "with tpu_strategy.scope():  # with TPU\n",
        "    model = build_inception_resnetv2_unet(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "#model = unet_model(input=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),)\n",
        "model.compile(optimizer=optimizer_f, loss=loss_f, metrics=metrics_f)\n",
        "\n",
        "results = model.fit(x=X_train, y=Y_train.astype(np.float32), validation_data=(X_val, Y_val.astype(np.float32)), batch_size=batch_s, \n",
        "                    epochs=epochs_s, callbacks=callbacks_f, verbose=1,)\n",
        "K.clear_session()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
